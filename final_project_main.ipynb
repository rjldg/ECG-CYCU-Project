{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "\n",
    "from utils import load_data, plot_history_tf, plot_heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cce8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Configuration\n",
    "# -------------------------\n",
    "IMG_SIZE = 224  # image height/width in pixels (square)\n",
    "IMAGE_DIR = Path(\"./ecg_images\")\n",
    "NPY_IMAGE_DIR = Path(\"./ecg_images_npy\")\n",
    "NPY_SIGNAL_DIR = Path(\"./ecg_signals_npy\")\n",
    "MODEL_SAVE_PATH = Path(\"./ecg_hybrid_model.h5\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "RANDOM_SEED = 42\n",
    "NUM_CLASSES = 15\n",
    "\n",
    "# Create directories\n",
    "IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NPY_IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NPY_SIGNAL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a52d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Part A: Processing 1D -> 2D images\n",
    "# -------------------------\n",
    "def normalize_signal(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32)\n",
    "    # standard score normalization (per-sample)\n",
    "    mean = x.mean()\n",
    "    std = x.std() if x.std() > 1e-6 else 1.0\n",
    "    return (x - mean) / std\n",
    "\n",
    "\n",
    "def signal_to_image(signal: np.ndarray, out_path: Path, img_size: int = IMG_SIZE):\n",
    "    \"\"\"Render a single 1D ECG signal to a square grayscale PNG of size (img_size, img_size).\n",
    "    We draw waveform with margins and no axes, then save as 224x224 grayscale PNG.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(img_size / 100, img_size / 100), dpi=100)\n",
    "    ax = plt.axes([0, 0, 1, 1])  # fill the figure\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # normalize between -1 and 1 for plotting\n",
    "    s = signal.astype(np.float32)\n",
    "    s = (s - s.min()) / (s.max() - s.min() + 1e-8)  # 0..1\n",
    "    s = s * 2 - 1  # -1..1\n",
    "\n",
    "    x = np.linspace(0, 1, len(s))\n",
    "    ax.plot(x, s, color='black', linewidth=1.2)\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "    # save\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    # optionally resize via PIL to ensure exact size\n",
    "    from PIL import Image\n",
    "    im = Image.open(out_path).convert('L')\n",
    "    im = im.resize((img_size, img_size), resample=Image.BICUBIC)\n",
    "    im.save(out_path)\n",
    "\n",
    "\n",
    "def create_image_dataset_from_signals(X: np.ndarray, y: np.ndarray, force_regen: bool = False) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Create image files for each 1D segment. Also save image arrays (npys) for fast training.\n",
    "    Returns (image_paths_array, labels_array) where image_paths_array is a list of file paths.\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for i in tqdm(range(len(X)), desc=\"Signals -> Images\"):\n",
    "        label = int(y[i])\n",
    "        class_dir = IMAGE_DIR / str(label)\n",
    "        class_dir.mkdir(parents=True, exist_ok=True)\n",
    "        fname = f\"sig_{i:06d}_lbl{label}.png\"\n",
    "        out_path = class_dir / fname\n",
    "        if (not out_path.exists()) or force_regen:\n",
    "            # normalize & render\n",
    "            s = normalize_signal(X[i])\n",
    "            signal_to_image(s, out_path, IMG_SIZE)\n",
    "\n",
    "        # save a fast numpy array as well\n",
    "        img = plt.imread(out_path)\n",
    "        img_arr = (img * 255).astype(np.uint8) if img.max() <= 1.0 else img.astype(np.uint8)\n",
    "        npy_path = NPY_IMAGE_DIR / f\"sig_{i:06d}_lbl{label}.npy\"\n",
    "        np.save(npy_path, img_arr)\n",
    "\n",
    "        image_paths.append(str(npy_path))\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(image_paths), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69cf2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Data loader: pairs of (signal, image) -> label\n",
    "# -------------------------\n",
    "\n",
    "def load_pair_dataset(signal_npy: np.ndarray, image_npy_paths: np.ndarray, labels: np.ndarray, batch_size: int, shuffle: bool = True):\n",
    "    \"\"\"Create tf.data.Dataset yielding ((signal, image), label)\n",
    "    signal_npy: np.ndarray of signals (N, 300)\n",
    "    image_npy_paths: array of paths to image .npy files (N,)\n",
    "    labels: (N,)\n",
    "    \"\"\"\n",
    "    def generator():\n",
    "        for sig, img_path, lbl in zip(signal_npy, image_npy_paths, labels):\n",
    "            img = np.load(img_path)\n",
    "            # ensure shape HxW or HxWxC\n",
    "            if img.ndim == 2:\n",
    "                img = img[..., None]\n",
    "            # normalize image to 0..1 float32\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            # normalize signal per-sample\n",
    "            sig = normalize_signal(sig)\n",
    "            yield (sig, img), lbl\n",
    "\n",
    "    output_signature = ((tf.TensorSpec(shape=(signal_npy.shape[1],), dtype=tf.float32),\n",
    "                         tf.TensorSpec(shape=(IMG_SIZE, IMG_SIZE, 1), dtype=tf.float32)),\n",
    "                        tf.TensorSpec(shape=(), dtype=tf.int32))\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(generator, output_signature=output_signature)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1024, seed=RANDOM_SEED)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ebb87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Model: 1D branch and 2D branch\n",
    "# -------------------------\n",
    "\n",
    "def build_1d_branch(input_shape=(300,)):\n",
    "    inp = layers.Input(shape=input_shape, name=\"ecg_signal\")\n",
    "    x = layers.Reshape((input_shape[0], 1))(inp)\n",
    "\n",
    "    # Conv blocks\n",
    "    for filters, k, pool in [(32, 7, 2), (64, 5, 2), (128, 5, None), (256, 3, None)]:\n",
    "        x = layers.Conv1D(filters, kernel_size=k, padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        if pool:\n",
    "            x = layers.MaxPool1D(pool_size=pool)(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    model = models.Model(inputs=inp, outputs=x, name='1d_branch')\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv2d_block(x, filters, kernel_size=3, pool=True):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    if pool:\n",
    "        x = layers.MaxPool2D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_2d_branch(input_shape=(IMG_SIZE, IMG_SIZE, 1)):\n",
    "    inp = layers.Input(shape=input_shape, name='ecg_image')\n",
    "    x = inp\n",
    "    for f in [32, 64, 128]:\n",
    "        x = conv2d_block(x, f, kernel_size=3, pool=True)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    model = models.Model(inputs=inp, outputs=x, name='2d_branch')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_hybrid_model(signal_shape=(300,), image_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=NUM_CLASSES):\n",
    "    branch1 = build_1d_branch(signal_shape)\n",
    "    branch2 = build_2d_branch(image_shape)\n",
    "\n",
    "    # combined\n",
    "    combined = layers.concatenate([branch1.output, branch2.output])\n",
    "    x = layers.Dense(256, activation='relu')(combined)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    out = layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = models.Model(inputs=[branch1.input, branch2.input], outputs=out, name='ecg_hybrid')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b42bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Training utility\n",
    "# -------------------------\n",
    "\n",
    "def train_hybrid(X_train, X_val, y_train, y_val, image_paths_train, image_paths_val):\n",
    "    train_ds = load_pair_dataset(X_train, image_paths_train, y_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_ds = load_pair_dataset(X_val, image_paths_val, y_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = build_hybrid_model()\n",
    "    opt = optimizers.Adam(learning_rate=1e-3)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(label_smoothing=0.02),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    cb = [\n",
    "        callbacks.EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True),\n",
    "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6),\n",
    "        callbacks.ModelCheckpoint(str(MODEL_SAVE_PATH), monitor='val_accuracy', save_best_only=True),\n",
    "        callbacks.TensorBoard(log_dir='./logs')\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=cb)\n",
    "\n",
    "    # evaluate\n",
    "    # build arrays for evaluation\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for (sig_batch, img_batch), lbl_batch in val_ds:\n",
    "        preds = model.predict([sig_batch, img_batch])\n",
    "        y_pred.extend(np.argmax(preds, axis=-1).tolist())\n",
    "        y_true.extend(lbl_batch.numpy().tolist())\n",
    "\n",
    "    plot_heat_map(np.array(y_true), np.array(y_pred))\n",
    "    plot_history_tf(history)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "830c0b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the ecg data of No.100\n",
      "loading the ecg data of No.101\n",
      "loading the ecg data of No.103\n",
      "loading the ecg data of No.105\n",
      "loading the ecg data of No.106\n",
      "loading the ecg data of No.107\n",
      "loading the ecg data of No.108\n",
      "loading the ecg data of No.109\n",
      "loading the ecg data of No.111\n",
      "loading the ecg data of No.112\n",
      "loading the ecg data of No.113\n",
      "loading the ecg data of No.114\n",
      "loading the ecg data of No.115\n",
      "loading the ecg data of No.116\n",
      "loading the ecg data of No.117\n",
      "loading the ecg data of No.119\n",
      "loading the ecg data of No.121\n",
      "loading the ecg data of No.122\n",
      "loading the ecg data of No.123\n",
      "loading the ecg data of No.124\n",
      "loading the ecg data of No.200\n",
      "loading the ecg data of No.201\n",
      "loading the ecg data of No.202\n",
      "loading the ecg data of No.203\n",
      "loading the ecg data of No.205\n",
      "loading the ecg data of No.208\n",
      "loading the ecg data of No.210\n",
      "loading the ecg data of No.212\n",
      "loading the ecg data of No.213\n",
      "loading the ecg data of No.214\n",
      "loading the ecg data of No.215\n",
      "loading the ecg data of No.217\n",
      "loading the ecg data of No.219\n",
      "loading the ecg data of No.220\n",
      "loading the ecg data of No.221\n",
      "loading the ecg data of No.222\n",
      "loading the ecg data of No.223\n",
      "loading the ecg data of No.228\n",
      "loading the ecg data of No.230\n",
      "loading the ecg data of No.231\n",
      "loading the ecg data of No.232\n",
      "loading the ecg data of No.233\n",
      "loading the ecg data of No.234\n",
      "X_train: (77872, 300)\n",
      "y_train: (77872,)\n",
      "label_set: (97340,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signals -> Images:   9%|â–‰         | 6981/77872 [08:12<1:23:25, 14.16it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileExistsError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\miniconda3\\envs\\ecg_cycu_project\\Lib\\pathlib.py:1311\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[31mFileExistsError\u001b[39m: [WinError 183] Cannot create a file when that file already exists: 'ecg_images\\\\12'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m np.save(NPY_SIGNAL_DIR / \u001b[33m'\u001b[39m\u001b[33my_test.npy\u001b[39m\u001b[33m'\u001b[39m, y_test)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 2) Create images for the train + test sets (images saved as .npy fast loaders)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m train_image_paths, train_labels_img = \u001b[43mcreate_image_dataset_from_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m test_image_paths, test_labels_img = create_image_dataset_from_signals(X_test, y_test)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Sanity: ensure labels align\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mcreate_image_dataset_from_signals\u001b[39m\u001b[34m(X, y, force_regen)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m out_path.exists()) \u001b[38;5;129;01mor\u001b[39;00m force_regen:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# normalize & render\u001b[39;00m\n\u001b[32m     57\u001b[39m     s = normalize_signal(X[i])\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[43msignal_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# save a fast numpy array as well\u001b[39;00m\n\u001b[32m     61\u001b[39m img = plt.imread(out_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36msignal_to_image\u001b[39m\u001b[34m(signal, out_path, img_size)\u001b[39m\n\u001b[32m     28\u001b[39m ax.set_xlim(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# save\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mout_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m plt.savefig(out_path, dpi=\u001b[32m100\u001b[39m, bbox_inches=\u001b[33m'\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m'\u001b[39m, pad_inches=\u001b[32m0\u001b[39m)\n\u001b[32m     33\u001b[39m plt.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\miniconda3\\envs\\ecg_cycu_project\\Lib\\pathlib.py:1320\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28mself\u001b[39m.mkdir(mode, parents=\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok=exist_ok)\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1318\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m   1319\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\miniconda3\\envs\\ecg_cycu_project\\Lib\\pathlib.py:870\u001b[39m, in \u001b[36mPath.is_dir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    867\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    868\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_dir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    871\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    872\u001b[39m \u001b[33;03m    Whether this path is a directory.\u001b[39;00m\n\u001b[32m    873\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    874\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 224x224 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Main script: orchestrate processing + training\n",
    "# -------------------------\n",
    "if __name__ == '__main__':\n",
    "    # 1) Load 1D data using provided utils\n",
    "    X_train, X_test, y_train, y_test = load_data(0.2, RANDOM_SEED)\n",
    "\n",
    "    # save raw signals for reproducibility\n",
    "    np.save(NPY_SIGNAL_DIR / 'X_train_signals.npy', X_train)\n",
    "    np.save(NPY_SIGNAL_DIR / 'X_test_signals.npy', X_test)\n",
    "    np.save(NPY_SIGNAL_DIR / 'y_train.npy', y_train)\n",
    "    np.save(NPY_SIGNAL_DIR / 'y_test.npy', y_test)\n",
    "\n",
    "    # 2) Create images for the train + test sets (images saved as .npy fast loaders)\n",
    "    train_image_paths, train_labels_img = create_image_dataset_from_signals(X_train, y_train)\n",
    "    test_image_paths, test_labels_img = create_image_dataset_from_signals(X_test, y_test)\n",
    "\n",
    "    # Sanity: ensure labels align\n",
    "    assert np.array_equal(train_labels_img, y_train), \"Train labels mismatch between signals and images\"\n",
    "    assert np.array_equal(test_labels_img, y_test), \"Test labels mismatch between signals and images\"\n",
    "\n",
    "    # 3) Train hybrid model\n",
    "    model, history = train_hybrid(X_train, X_test, y_train, y_test, train_image_paths, test_image_paths)\n",
    "\n",
    "    print(\"Training finished. Best model saved to:\", MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a8003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_cycu_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
